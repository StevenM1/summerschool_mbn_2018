{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Modelling the behavioral data\n",
    "\n",
    "In Part 1, we had a look at options for preprocessing fMRI data. Now, let's turn to the other essential ingredient of model-based fMRI-analyses: modelling behavioral data.\n",
    "\n",
    "There are Python packages that allows you to easily fit decision-making models such as the drift diffusion model (DDM). Most notably, [`hddm`](http://ski.clps.brown.edu/hddm_docs/) developed at Brown University is a widely used package.\n",
    "\n",
    "However, `DMC` (as used in the tutorials earlier this week) has some advantages\\*. For example, `DMC` offers much more models (including a multitude of LBA-model variants, stop-signal models and ex-Gaus). So you might want to use `DMC` to fit a model, and then use `Nipype` to create your fMRI-processing pipeline.\n",
    "\n",
    "<sub><sup>\\* and disadvantages - it doesn't support modelling single-trial regressors out of the box at the moment of writing</sup></sub>\n",
    "\n",
    "So, we're just going to use `DMC` to fit the behavioral data for now. Note that _this_ notebook you're looking at right now (`Part 2. Modelling the behavioral data`) is actually _not_ an interactive Python notebook ('.ipynb'), but it is an interactive **R** notebook ('.irnb')! That means that instead of running Python code, we can run R-code in here!\n",
    "\n",
    "For example, to draw some random numbers from a normal distribution (4,1), we can use this R-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnorm(10, 4, 1)\n",
    "\n",
    "# note further that the help-function works as usual:\n",
    "?rnorm\n",
    "\n",
    "# and plotting is done in-line\n",
    "plot(1:10, 1:10, main='In line plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So let's use DMC to fit the behavioral data\n",
    "\n",
    "First, set-up some directories, so R knows where to find DMC, the data, and where to store the results of these analyses (the 'res(ults)Dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projDir <- '/home/neuro/nipype_tutorial'\n",
    "dataDir <- file.path('/data', 'bids')\n",
    "resDir <- file.path('/data', 'behavior_fits')\n",
    "dir.create(resDir, showWarnings=FALSE)\n",
    "dmcDir <- 'DMC-MBN18'\n",
    "\n",
    "# Load dmc, load the DDM model\n",
    "setwd(dmcDir)\n",
    "source('dmc/dmc.R')\n",
    "source('dmc/models/DDM/ddm.R')\n",
    "library(rtdists)\n",
    "setwd(projDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data, and reformat to a DMC-approved form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dat <- read.csv(file.path(dataDir, 'behavior.tsv'), sep='\\t')\n",
    "\n",
    "# Remove unnecessary columns, rename according to DMC's wishes\n",
    "dat <- dat[,c('pp', 'stimulus', 'cond', 'response', 'RT')]\n",
    "colnames(dat) <- c('s', 'S', 'cue', 'R', 'RT')\n",
    "\n",
    "# Remove all extremely fast responses (<.15s)\n",
    "dat <- dat[dat$RT>.15,]\n",
    "\n",
    "# Ensure the following columns are of type factor, and rename the stimulus/response factors to S1/S2 and R1/R2\n",
    "dat$s <- factor(dat$s)\n",
    "dat$cue <- factor(dat$cue, levels=c('spd', 'acc'))\n",
    "levels(dat$S) <- c('S1', 'S2')\n",
    "levels(dat$R) <- c('R1', 'R2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The next step is to set up the model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up model: specify what 'factors' are in the experiment\n",
    "factors <- list(S=c('S1', 'S2'), cue=c('spd', 'acc'))\n",
    "responses <- c(\"R1\", \"R2\")\n",
    "match.map = list(M=list(S1=\"R1\", S2=\"R2\"))  # Specify which response is 'correct' for which stimulus\n",
    "\n",
    "# set-up p.map. This tells DMC which parameters should vary across which conditions. \n",
    "# Note that we're allowing v, a, and t0 to vary across cue-condition\n",
    "p.map <- list(a='cue',\n",
    "              v='cue',\n",
    "              t0='cue',\n",
    "              z='1',\n",
    "              sz='1',\n",
    "              sv='1',\n",
    "              st0='1',\n",
    "              d='1')\n",
    "\n",
    "# Let's not estimate between-trial variabilities. Further, fix z to 0.5 (= 0.5 * a)\n",
    "constants <- c(st0=0,\n",
    "               sz=0,\n",
    "               sv=0,\n",
    "               d=0,\n",
    "               z=0.5)\n",
    "\n",
    "# And this is our model\n",
    "model <- model.dmc(constants=constants,\n",
    "                   match.map=match.map,\n",
    "                   factors=factors,\n",
    "                   responses=responses,\n",
    "                   p.map = p.map,\n",
    "                   type=\"norm\")\n",
    "\n",
    "# combine model and data\n",
    "data.model <- data.model.dmc(data=dat, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good! Two thresholds (one for speed, one for accuracy), a drift rate, and a non-decision time. \n",
    "\n",
    "##### Now, we need to set-up priors for these parameters.\n",
    "\n",
    "Let's use some mildly informed priors (cf. Matzke & Wagenmakers, 2009)\n",
    "\n",
    "- v ~ TN(2.5, 3)  truncated lower at 0\n",
    "- a ~ TN(1, 2)   truncated lower at 0\n",
    "- t0 ~ TN(0.25, 1)  truncated lower at 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.prior <- prior.p.dmc(\n",
    "  dists = rep('tnorm', 6),\n",
    "  p1=c(v.spd=2.5, v.acc=2.5, a.spd=1.00, a.acc=1.00, t0.spd=0.25, t0.acc=0.25), # these are the means\n",
    "  p2=c(v.spd=3.0, v.acc=2.5, a.spd=2.00, a.acc=2.00, t0.spd=0.25, t0.acc=0.25),  # and these the SDs\n",
    "  lower=c(0, 0, 0, 0, 0, 0),  # lower bound is 0 for v, a, t0\n",
    "  upper=c(NA, NA, NA, NA, NA, NA)  # no upper bound\n",
    ")\n",
    "\n",
    "# What do they look like?\n",
    "par(mfrow=c(3,2))\n",
    "for(i in 1:length(p.prior)) plot.prior(i, p.prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems about right. Now, since fMRI sessions generally consist of very few trials (40 per speed/accuracy condition), we want to estimate these parameters in a hierarchical manner. That means that we are using group-level distributions to inform where an individual subject's parameter is likely to be.\n",
    "\n",
    "DMC handles most of the 'magic' of hierarchical fitting. The only thing you need to do is provide priors on what you think the group-level distribution of each parameter looks like. This is typically a bit hard to do. But let's use the following priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, I use similar priors for mu as for the subject-level, and Gamma(1,1) for sigma\n",
    "mu.prior <- prior.p.dmc(\n",
    "  dists = rep('tnorm', 6),\n",
    "  p1=c(v.spd=2.5, v.acc=2.5, a.spd=1.00, a.acc=1.00, t0.spd=0.25, t0.acc=0.25),\n",
    "  p2=c(v.spd=3.0, v.acc=2.5, a.spd=2.00, a.acc=2.00, t0.spd=0.25, t0.acc=0.25),\n",
    "  lower=c(0, 0, 0, 0, 0, 0),\n",
    "  upper=c(NA, NA, NA, NA, NA, NA)\n",
    ")\n",
    "sigma.prior <- prior.p.dmc(\n",
    "  dists = rep('gamma', 6),\n",
    "  p1 = c(v.spd=1, v.acc=1, a.spd=1, a.acc=1, t0.spd=1, t0.acc=1),\n",
    "  p2 = c(v.spd=1, v.acc=1, a.spd=1, a.acc=1, t0.spd=1, t0.acc=1),\n",
    "  lower = rep(NA, 6),\n",
    "  upper = rep(NA, 6)\n",
    ")\n",
    "# Combine these in a list for DMC\n",
    "pp.prior <- list(mu.prior, sigma.prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we're ready to start sampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsamples0 <- h.samples.dmc(nmc=250, p.prior, data.model, thin=1, pp.prior=pp.prior)\n",
    "\n",
    "# start with a burn-in of 250 samples with migration turned on both at the subject and hyper level\n",
    "hsamples1 <- h.run.dmc(hsamples0, cores=3, p.migrate=0.05, h.p.migrate=0.05, report=1)  # hsamples1 = burn-in\n",
    "# This takes a while...\n",
    "\n",
    "# Nothing stuck?\n",
    "h.pick.stuck.dmc(hsamples1, start=200)\n",
    "par(mfrow=c(2,2))\n",
    "for(i in 1:length(hsamples1)) {\n",
    "    plot.dmc(hsamples1, pll.chain=TRUE, subject = i, start=50)\n",
    "    title(paste0('Subject ', names(hsamples1)[i]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran this before, there were no stuck chains and 250 burn-in iterations was sufficient. However, if you find stuck chains, you may want to add some extra burn-in samples before you continue.\n",
    "\n",
    "Otherwise, let's sample from the posterior now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get 1000 samples from posterior\n",
    "hsamples2 <- h.run.dmc(h.samples.dmc(samples = hsamples1, nmc=1000, add=FALSE),  # don't add to burn-in but start counting from 0\n",
    "                       cores=3, p.migrate=0.00, h.p.migrate=0.00, report=1)  # turn off migration in real sampling\n",
    "\n",
    "# Let's save these results\n",
    "save(hsamples0, hsamples1, hsamples2, file=file.path(resDir, 'samples.Rdata'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspection\n",
    "Now that the sampling is done, we need to inspect whether everything went right. MCMC is a bit error prone - chains can get stuck, for example. If sampling did not go well, you *cannot* interpret the resulting parameters. One thing you want to do is inspect Gelman's diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmdiag = h.gelman.diag.dmc(hsamples2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you want them to be smaller than 1.1 (at most); I usually prefer values of 1.05 and below.\n",
    "\n",
    "What about the effective sample sizes? Did we sample sufficient (independent) samples from the posteriors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = effectiveSize.dmc(hsamples2)\n",
    "do.call(rbind, es)  # this prints a data frame with all effective sample sizes per participant/parameter combination\n",
    "min(do.call(rbind, es))  # prints the smallers number in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\>500 samples is fine for now\n",
    "\n",
    "It's also important to visualize and inspect your chains. First, plot the chains at the subject level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)  # suppresses some warnings\n",
    "for(pp in names(hsamples2)) {\n",
    "    par(mfrow=c(1,1))\n",
    "    plot.dmc(hsamples2, hyper=FALSE, subject=pp, pll.chain=TRUE)\n",
    "    mtext(paste0('Participant ', pp, ' posterior log likelihoods of all chains'), outer=TRUE, line=-1.5)\n",
    "    plot.dmc(hsamples2,hyper=FALSE,subject=pp, layout=c(4,2), density = TRUE)\n",
    "    mtext(paste0('Participant ', pp), outer=TRUE, line=-1.5)\n",
    "}\n",
    "options(warn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you want to see are \"big hairy caterpillars\" (left columns), that are stable (no drift up or down) and with no stuck chains ('hairs' that dont move). In the right columns, you want smooth densities.\n",
    "\n",
    "Let's also plot the chains of the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)  # suppresses some warnings\n",
    "par(mfrow=c(1,1))\n",
    "plot.dmc(hsamples2, hyper=TRUE, pll.chain=TRUE)\n",
    "mtext(paste0('Hyper posterior log likelihoods of all chains'), outer=TRUE, line=-1.5)\n",
    "plot.dmc(hsamples2, hyper=TRUE, layout=c(4,2), density = TRUE)\n",
    "mtext(paste0('Hyper'), outer=TRUE, line=-1.5)\n",
    "options(warn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, all the previous inspections indicate that sampling went fine. Now, what about the quality of fits? In order to visualize this, we first generate 'posterior predictives', and then plot these against the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.posterior.preds <- h.post.predict.dmc(hsamples2, n.post = 100, cores=4)\n",
    "plot.pp.dmc(h.posterior.preds, layout=c(2,2), x.min.max = c(0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the fit?\n",
    "\n",
    "Finally, for model-based analyses in Part 4 of this tutorial, we need parameters. Let's save these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ <- summary.dmc(hsamples2)\n",
    "\n",
    "MAP.per.sub <- do.call(rbind, lapply(summ, function(x) x$statistics[,1]))\n",
    "write.csv(MAP.per.sub, file=file.path(resDir, 'parameters_per_subject.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "The above fit is (I think) pretty nice, especially considering that we have only 80 trials per participant. However, it's not necessarily the _best_ model; we could consider _not_ allowing v, a, or t0 to vary between conditions, and do a formal model comparison to see which model specification has the best trade-off between complexity and quality of fit (using, e.g., DIC).\n",
    "\n",
    "As an optional exercise, can you figure out which model specification fits the data best?\n",
    "\n",
    "In order to find this model, you should:\n",
    "\n",
    " - Change the p.map\n",
    " - Change the priors \n",
    " \n",
    "And re-run the analyses above. Don't forget to *save* the current fit (hsamples2 is most important), and *not* overwrite `/data/behavioral_data/samples.Rdata` - since you need it for model comparisons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "The tutorial in `DMC` is very helpful: [DMC](https://osf.io/pbwx8/?view_only=6a269eca82a44ad3992b69c7a5781af5)\n",
    "\n",
    "Also, check out `hddm` if you want to do this type of stuff in Python: [HDDM](http://ski.clps.brown.edu/hddm_docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
